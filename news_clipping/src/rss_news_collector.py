import feedparser
import json
from datetime import datetime
from pathlib import Path
import re

class RSSNewsCollector:
    def __init__(self):
        # RSS í”¼ë“œ URL ëª©ë¡
        self.rss_feeds = {
            "ì—°í•©ë‰´ìŠ¤_ê²½ì œ": "https://www.yonhapnewstv.co.kr/category/news/economy/feed/",
            "í•œêµ­ê²½ì œ_ì‚°ì—…": "https://rss.hankyung.com/feed/economy.xml",
            "ì´íˆ¬ë‰´ìŠ¤_ì—ë„ˆì§€": "http://www.e2news.com/rss/allArticle.xml"
        }
        
        # í‚¤ì›Œë“œ í•„í„°
        self.keywords = {
            "energy": ["ì‹ ì¬ìƒì—ë„ˆì§€", "íƒœì–‘ê´‘", "í’ë ¥", "ESS", "ì—ë„ˆì§€ì •ì±…", "RE100"],
            "defense": ["ë°©ìœ„ì‚°ì—…", "K-ë°©ì‚°", "í•œí™”ì‹œìŠ¤í…œ", "LIGë„¥ìŠ¤ì›", "KAI", "ë°©ì‚°ìˆ˜ì¶œ"],
            "insurance": ["ë³´í—˜ì¤‘ê°œì‚¬", "ë³´í—˜ìƒí’ˆ", "ì¬ë³´í—˜", "IFRS17", "ì¸ìŠˆì–´í…Œí¬"]
        }
        
        # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        self.output_dir = Path(__file__).parent.parent / 'output'
        self.output_dir.mkdir(exist_ok=True)

    def fetch_rss_feed(self, feed_url):
        """RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            feed = feedparser.parse(feed_url)
            return feed.entries
        except Exception as e:
            print(f"âŒ RSS í”¼ë“œ ìˆ˜ì§‘ ì˜¤ë¥˜ ({feed_url}): {str(e)}")
            return []

    def matches_keywords(self, text):
        """í…ìŠ¤íŠ¸ê°€ í‚¤ì›Œë“œ í•„í„°ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        for category, keywords in self.keywords.items():
            for keyword in keywords:
                if keyword in text:
                    return True, category
        return False, None

    def clean_html(self, text):
        """HTML íƒœê·¸ë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
        clean = re.compile('<.*?>')
        return re.sub(clean, '', text)

    def collect_news(self):
        """ëª¨ë“  RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  í•„í„°ë§í•©ë‹ˆë‹¤."""
        collected_news = []
        
        print("ğŸ” ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        
        for source, feed_url in self.rss_feeds.items():
            print(f"\nğŸ“° {source} í”¼ë“œ ìˆ˜ì§‘ ì¤‘...")
            entries = self.fetch_rss_feed(feed_url)
            
            for entry in entries:
                title = self.clean_html(entry.title)
                matches, category = self.matches_keywords(title)
                
                if matches:
                    news_item = {
                        "title": title,
                        "link": entry.link,
                        "published": entry.get('published', ''),
                        "summary": self.clean_html(entry.get('summary', '')),
                        "source": source,
                        "category": category
                    }
                    collected_news.append(news_item)
        
        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.output_dir / f"news_collection_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(collected_news, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ¨ ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(collected_news)}ê±´ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_file}")
        
        return collected_news

if __name__ == "__main__":
    collector = RSSNewsCollector()
    collector.collect_news() 